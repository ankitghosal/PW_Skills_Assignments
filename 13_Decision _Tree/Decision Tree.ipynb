{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e443e68c-66a4-4bf0-b0fd-ac33caef70fb",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649a3dca-3cec-4470-ab9d-cee8d8fc9cd0",
   "metadata": {},
   "source": [
    "##\n",
    "### Question 1: What is a Decision Tree, and how does it work in the context of classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8281042b-e87c-4fb8-9dbe-0c03f4536dd5",
   "metadata": {},
   "source": [
    "A **Decision Tree** is a supervised learning algorithm used for **classification and regression tasks**. It works by **splitting data into branches** based on feature values, forming a tree-like structure where:\n",
    "\n",
    "* **Root Node** → Represents the entire dataset.\n",
    "* **Internal Nodes** → Represent decisions or tests on features.\n",
    "* **Leaf Nodes** → Represent final outcomes or class labels.\n",
    "\n",
    "In classification, the tree divides data based on measures like **Gini Impurity** or **Entropy**, aiming to create **pure subsets** where most instances belong to a single class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39809a84-2a06-4d65-aeb3-93a1704c1e14",
   "metadata": {},
   "source": [
    "##\n",
    "### Question 2: Explain the concepts of Gini Impurity and Entropy as impurity measures. How do they impact the splits in a Decision Tree?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45aeadb9-360e-4b75-b6c9-c82d500b4152",
   "metadata": {},
   "source": [
    "**Gini Impurity** and **Entropy** are metrics used to measure the **purity or disorder** of data at a node in a Decision Tree — they help decide the **best split**.\n",
    "\n",
    "* **Gini Impurity:**\n",
    "  Measures how often a randomly chosen sample would be **incorrectly classified** if labeled randomly based on class distribution.<br>\n",
    "$$[\n",
    "  Gini = 1 - \\sum p_i^2\n",
    "  ]$$\n",
    "  <br>Lower Gini → purer node.\n",
    "\n",
    "* **Entropy:**\n",
    "  Measures the **amount of uncertainty** or randomness in data.\n",
    " $$ [\n",
    "  Entropy = -\\sum p_i \\log_2(p_i)\n",
    "  ]$$\n",
    "  Lower entropy → higher purity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08165b51-d633-4377-a2b1-94df42180b47",
   "metadata": {},
   "source": [
    "##\n",
    "### Question 3: What is the difference between Pre-Pruning and Post-Pruning in Decision Trees? Give one practical advantage of using each.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adfc4f8-6a80-4fd8-9c16-2d20879d5303",
   "metadata": {},
   "source": [
    "**Pre-Pruning (Early Stopping):**\n",
    "Pre-pruning stops the tree from growing once a certain condition is met (e.g., maximum depth, minimum samples per split).\n",
    "\n",
    "* **Advantage:** Prevents overfitting early, making the model simpler and faster to train.\n",
    "\n",
    "**Post-Pruning (Reduced Error Pruning):**\n",
    "Post-pruning allows the tree to grow fully, then removes branches that don’t improve accuracy on validation data.\n",
    "\n",
    "* **Advantage:** Produces a more optimal and generalizable model by evaluating actual performance before trimming.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5886b5b2-0106-448e-b44a-119ca0581f89",
   "metadata": {},
   "source": [
    "##\n",
    "### Question 4: What is Information Gain in Decision Trees, and why is it important for choosing the best split?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb92576-543c-4f8e-aa65-9419acab8274",
   "metadata": {},
   "source": [
    "**Information Gain (IG)** measures how much **uncertainty (entropy)** in the target variable is reduced after splitting a dataset based on a feature. It helps determine **which feature provides the most useful information** for classification.\n",
    "\n",
    "$$[\n",
    "Information\\ Gain = Entropy(Parent) - \\sum \\frac{N_i}{N} \\times Entropy(Child_i)\n",
    "]$$\n",
    "\n",
    "* A **higher IG** means the feature provides a better split.\n",
    "* Decision Trees select the feature with the **maximum Information Gain** at each node, ensuring the tree becomes more **pure and efficient** in separating classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4388299f-49fd-436f-a8c8-4751432ce959",
   "metadata": {},
   "source": [
    "##\n",
    "### Question 5: What are some common real-world applications of Decision Trees, and what are their main advantages and limitations?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d403aeb-8900-4348-b0df-5b924f3c9130",
   "metadata": {},
   "source": [
    "**Applications:**\n",
    "\n",
    "* **Finance:** Credit risk assessment and loan approval.\n",
    "* **Healthcare:** Disease diagnosis based on symptoms.\n",
    "* **Marketing:** Customer segmentation and churn prediction.\n",
    "* **Manufacturing:** Quality control and fault detection.\n",
    "\n",
    "**Advantages:**\n",
    "\n",
    "* Easy to **understand, visualize, and interpret**.\n",
    "* Requires little data preprocessing (no scaling or normalization).\n",
    "* Handles **numerical and categorical** data effectively.\n",
    "\n",
    "**Limitations:**\n",
    "\n",
    "* Prone to **overfitting** if not pruned.\n",
    "* **Unstable** — small data changes can alter the tree structure.\n",
    "* May **favor features** with more levels (biased splits).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0898458-a680-4205-8913-bd883c25f3c4",
   "metadata": {},
   "source": [
    "##\n",
    "### Dataset Info:\n",
    "* Iris Dataset for classification tasks (sklearn.datasets.load_iris() or\n",
    "provided CSV).\n",
    "* Boston Housing Dataset for regression tasks\n",
    "(sklearn.datasets.load_boston() or provided CSV)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930ef9e4-4368-4df9-b0c3-b4e0f850d7ed",
   "metadata": {},
   "source": [
    "##\n",
    "### Question 6: Write a Python program to:\n",
    "* Load the Iris Dataset\n",
    "* Train a Decision Tree Classifier using the Gini criterion\n",
    "* Print the model’s accuracy and feature importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "494d9574-a7f5-4cfe-9f57-cd0583ba7b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 1.0\n",
      "\n",
      "Feature Importances:\n",
      "sepal length (cm): 0.0000\n",
      "sepal width (cm): 0.0167\n",
      "petal length (cm): 0.9061\n",
      "petal width (cm): 0.0772\n"
     ]
    }
   ],
   "source": [
    "# --- Import Libraries ---\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# --- Load the Iris Dataset ---\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# --- Split into Train and Test Sets ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Train Decision Tree Classifier (using Gini) ---\n",
    "model = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# --- Predict and Evaluate ---\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# --- Display Results ---\n",
    "print(\"Decision Tree Accuracy:\", accuracy)\n",
    "print(\"\\nFeature Importances:\")\n",
    "for feature, importance in zip(iris.feature_names, model.feature_importances_):\n",
    "    print(f\"{feature}: {importance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc73679-9e5c-483d-8480-3832bd5f4fec",
   "metadata": {},
   "source": [
    "##\n",
    "### Question 7: Write a Python program to:\n",
    "* Load the Iris Dataset\n",
    "* Train a Decision Tree Classifier with max_depth=3 and compare its accuracy to\n",
    "a fully-grown tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5b98348-c58d-4eb5-ab2e-5db8d4b909ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Fully Grown Tree: 1.0\n",
      "Accuracy of Pruned Tree (max_depth=3): 1.0\n"
     ]
    }
   ],
   "source": [
    "# --- Load the Iris Dataset ---\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# --- Split Data ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Fully Grown Tree ---\n",
    "full_tree = DecisionTreeClassifier(random_state=42)\n",
    "full_tree.fit(X_train, y_train)\n",
    "full_pred = full_tree.predict(X_test)\n",
    "full_acc = accuracy_score(y_test, full_pred)\n",
    "\n",
    "# --- Pruned Tree (max_depth=3) ---\n",
    "pruned_tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "pruned_tree.fit(X_train, y_train)\n",
    "pruned_pred = pruned_tree.predict(X_test)\n",
    "pruned_acc = accuracy_score(y_test, pruned_pred)\n",
    "\n",
    "# --- Print Comparison ---\n",
    "print(\"Accuracy of Fully Grown Tree:\", full_acc)\n",
    "print(\"Accuracy of Pruned Tree (max_depth=3):\", pruned_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75bebaf-7064-4503-b14b-3d4b5de57cde",
   "metadata": {},
   "source": [
    "##\n",
    "### Question 8: Write a Python program to:\n",
    "* Load the Boston Housing Dataset\n",
    "* Train a Decision Tree Regressor\n",
    "* Print the Mean Squared Error (MSE) and feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2dba4f5-7a1c-42f2-bbc4-0c268e78e366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 10.416078431372549\n",
      "\n",
      "Feature Importances:\n",
      "CRIM: 0.0513\n",
      "ZN: 0.0034\n",
      "INDUS: 0.0058\n",
      "CHAS: 0.0000\n",
      "NOX: 0.0271\n",
      "RM: 0.6003\n",
      "AGE: 0.0136\n",
      "DIS: 0.0707\n",
      "RAD: 0.0019\n",
      "TAX: 0.0125\n",
      "PTRATIO: 0.0110\n",
      "B: 0.0090\n",
      "LSTAT: 0.1933\n"
     ]
    }
   ],
   "source": [
    "# --- Import Libraries ---\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# --- Load Boston Housing Dataset ---\n",
    "boston = fetch_openml(name='boston', version=1, as_frame=True)\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "# --- Split Data ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Train Decision Tree Regressor ---\n",
    "regressor = DecisionTreeRegressor(random_state=42)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# --- Predict and Evaluate ---\n",
    "y_pred = regressor.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# --- Display Results ---\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"\\nFeature Importances:\")\n",
    "for feature, importance in zip(X.columns, regressor.feature_importances_):\n",
    "    print(f\"{feature}: {importance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88920bd1-7c2c-4e28-aeaa-ff4e9e1692c5",
   "metadata": {},
   "source": [
    "##\n",
    "### Question 9: Write a Python program to:\n",
    "* Load the Iris Dataset\n",
    "* Tune the Decision Tree’s max_depth and min_samples_split using\n",
    "GridSearchCV\n",
    "* Print the best parameters and the resulting model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ff8e9ec-7fa0-45b5-ba14-b45e53355562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 4, 'min_samples_split': 2}\n",
      "Best Cross-Validation Accuracy: 0.9416666666666668\n",
      "Test Set Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# --- Import Libraries ---\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# --- Load the Iris Dataset ---\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# --- Split Data ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Define Parameter Grid ---\n",
    "param_grid = {\n",
    "    'max_depth': [2, 3, 4, 5, None],\n",
    "    'min_samples_split': [2, 3, 4, 5, 10]\n",
    "}\n",
    "\n",
    "# --- Initialize Model and Grid Search ---\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=DecisionTreeClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "# --- Fit the Model ---\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# --- Best Parameters and Accuracy ---\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
    "print(\"Test Set Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c301047d-b451-40c2-8ff1-439e87bc29df",
   "metadata": {},
   "source": [
    "##\n",
    "### Question 10: Imagine you’re working as a data scientist for a healthcare company that\n",
    "wants to predict whether a patient has a certain disease. You have a large dataset with\n",
    "mixed data types and some missing values.\n",
    "Explain the step-by-step process you would follow to:\n",
    "* Handle the missing values\n",
    "* Encode the categorical features\n",
    "* Train a Decision Tree model\n",
    "* Tune its hyperparameters\n",
    "* Evaluate its performance\n",
    "And describe what business value this model could provide in the real-world\n",
    "setting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d13cd3fa-0482-47de-90c5-a9f25541644f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'classifier__criterion': 'gini', 'classifier__max_depth': 2, 'classifier__min_samples_split': 2}\n",
      "\n",
      "Model Accuracy: 0.6666666666666666\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.75      0.75      0.67         3\n",
      "weighted avg       0.83      0.67      0.67         3\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1 1]\n",
      " [0 1]]\n",
      "\n",
      "✅ BUSINESS VALUE:\n",
      "- Enables early detection of diseases through data-driven insights.\n",
      "- Helps allocate medical resources efficiently.\n",
      "- Improves diagnostic accuracy and supports personalized treatment plans.\n",
      "- Provides healthcare professionals with interpretable, rule-based decisions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Decision Tree Pipeline for Disease Prediction ---\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# ---------------------------\n",
    "# Step 1: Simulate healthcare dataset\n",
    "# ---------------------------\n",
    "data = {\n",
    "    'Age': [25, 40, 35, np.nan, 50, 45, 60, np.nan, 30, 55],\n",
    "    'Gender': ['Male', 'Female', 'Female', 'Male', 'Male', 'Female', np.nan, 'Female', 'Male', 'Female'],\n",
    "    'BloodPressure': [120, 130, np.nan, 110, 140, 125, 150, 135, np.nan, 145],\n",
    "    'Cholesterol': ['High', 'Normal', 'High', 'Normal', np.nan, 'High', 'High', 'Normal', 'High', 'Normal'],\n",
    "    'Disease': [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('Disease', axis=1)\n",
    "y = df['Disease']\n",
    "\n",
    "# Identify column types\n",
    "num_cols = ['Age', 'BloodPressure']\n",
    "cat_cols = ['Gender', 'Cholesterol']\n",
    "\n",
    "# ---------------------------\n",
    "# Step 2: Preprocessing (handle missing values + encoding)\n",
    "# ---------------------------\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_cols),\n",
    "        ('cat', categorical_transformer, cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# Step 3: Model + Pipeline setup\n",
    "# ---------------------------\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('classifier', dt)])\n",
    "\n",
    "# ---------------------------\n",
    "# Step 4: Train/Test Split\n",
    "# ---------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# ---------------------------\n",
    "# Step 5: Hyperparameter Tuning\n",
    "# ---------------------------\n",
    "param_grid = {\n",
    "    'classifier__max_depth': [2, 3, 4, 5, None],\n",
    "    'classifier__min_samples_split': [2, 4, 6],\n",
    "    'classifier__criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# ---------------------------\n",
    "# Step 6: Evaluation\n",
    "# ---------------------------\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"\\nModel Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# ---------------------------\n",
    "# Step 7: Business Value Summary\n",
    "# ---------------------------\n",
    "print(\"\"\"\n",
    "✅ BUSINESS VALUE:\n",
    "- Enables early detection of diseases through data-driven insights.\n",
    "- Helps allocate medical resources efficiently.\n",
    "- Improves diagnostic accuracy and supports personalized treatment plans.\n",
    "- Provides healthcare professionals with interpretable, rule-based decisions.\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
